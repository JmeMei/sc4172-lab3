# sc4172-lab3
# Tiny ML on Arduino: Gesture Recognition

This project demonstrates how to implement gesture recognition using TinyML on an Arduino Nano 33 BLE Sense board. The process involves collecting sensor data, training a TensorFlow Lite model in Google Colab, converting the model for embedded use, and deploying it to the Arduino for real-time inference.

## Project Structure

The main components of this project are:

1.  **Data Collection:** Gathering IMU (Inertial Measurement Unit) data for different gestures (e.g., 'punch', 'flex'). This data is typically stored in `.csv` format.
2.  **Python Environment Setup:** Setting up necessary libraries in Google Colab.
3.  **Data Preparation:** Loading, cleaning, normalizing, and splitting the gesture data for training and testing.
4.  **Model Training:** Building and training a neural network using TensorFlow/Keras.
5.  **Model Evaluation:** Visualizing training performance and verifying predictions.
6.  **Model Conversion & Deployment:** Converting the trained model to TensorFlow Lite and encoding it into an Arduino-compatible header file for embedded use.

## Setup and Execution

To run this project, follow these steps:

### 1. Setup Python Environment

Run the Python environment setup cell in the Colab notebook to install necessary dependencies:

```python
# Setup environment
!apt-get -qq install xxd
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf
print(f"Using TensorFlow version: {tf.__version__}")
```

### 2. Upload Data

Upload your gesture data files (`punch.csv`, `flex.csv`, etc.) to the `/content/` directory in your Colab environment. The notebook expects these files to be available.

### 3. Data Preparation

The notebook includes cells to parse and prepare the data. It will:
*   Read each `.csv` file corresponding to a gesture.
*   Convert relevant columns to numeric types, coercing errors to `NaN`.
*   Drop any rows containing `NaN` values to ensure data integrity.
*   Normalize the acceleration and gyroscope data to a 0-1 range.
*   One-hot encode the gesture labels.
*   Randomize and split the data into training, validation, and testing sets (60%, 20%, 20% respectively).

```python
# Relevant code for data preparation is in cell `AGChd1FAk5_j`
```

### 4. Train Neural Network

A sequential Keras model is defined and trained using the prepared data. The model consists of Dense layers with `relu` and `softmax` activations.

```python
# Relevant code for model training is in cell `kGNFa-lX24Qo`
```

### 5. Verify Model Performance

After training, the notebook generates plots to visualize:
*   **Training and Validation Loss:** To observe how the model's error decreases over epochs.
*   **Training and Validation Mean Absolute Error (MAE):** Another metric to gauge model accuracy.
*   **Predicted vs. Actual Values:** A plot comparing the model's predictions against the true labels for the test dataset, showing per-sample accuracy.

```python
# Relevant code for verification is in cells `bvFNHXoQzmcM`, `c3xT7ue2zovd`, `mBjCf1-2zx9C`, `V3Y0CCWJz2EK`
```

### 6. Convert and Encode Model for Arduino

The trained TensorFlow model is converted to a TensorFlow Lite format and then encoded into a C header file (`model.h`). This file can be included in an Arduino sketch.

To convert your `.tflite` model to a C header file, use the following command in your terminal:

```sh
xxd -i gesture_model.tflite > gesture_model.h
```

This file can be included in an Arduino sketch.

## Using the Model on Arduino

1.  Download the `model.h` file generated by the Colab notebook.
2.  Include this file in your Arduino project.
3.  Refer to the Arduino TensorFlow Lite tutorials (e.g., [arduino/ArduinoTensorFlowLiteTutorials](https://github.com/arduino/ArduinoTensorFlowLiteTutorials/)) for instructions on integrating and running the TinyML model on your Arduino Nano 33 BLE Sense board to perform real-time gesture recognition.